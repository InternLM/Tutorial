# XTuner 微调个人小助手认知任务
记录复现过程并截图。

## 基础任务（完成此任务即完成闯关并获得 100 算力点）

- 使用 XTuner 微调 InternLM2-Chat-1.8B 实现自己的小助手认知，如下图所示（图中的`尖米`需替换成自己的昵称），记录复现过程并截图。


![image](https://github.com/user-attachments/assets/d7c80ea1-761b-4225-974a-620658b2e99d)

## 进阶任务（闯关不要求完成此任务）

- 用自己感兴趣的知识对基座模型进行增量预训练微调
- 在资源允许的情况下，尝试实现多卡微调与分布式微调
- 将自我认知的模型上传到 OpenXLab，并将应用部署到 OpenXLab
- 参与社区共建，获取浦语 api 创建自己的数据用于微调（有创意的成果有机会获得优秀学员提名）

> OpenXLab 部署教程：https://github.com/InternLM/Tutorial/tree/camp2/tools/openxlab-deploy

## 闯关材料提交 (完成任务并且提交材料视为闯关成功)

- 请将作业发布到知乎、CSDN等任一社交媒体，将作业链接提交到以下问卷，助教老师批改后将获得 100 算力点奖励！！！
- 提交地址：