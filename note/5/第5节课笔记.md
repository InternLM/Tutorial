## 1.前言

本次课是基础课程最后一次内容，大模型的部署。本次课程所使用最基础的大模型 InternLM-7B，是最小的模型。但它的权重大小仍然有13.6 GB。

以我自己的电脑为例，我电脑的显卡是, RTX3060 12GB。入门款的消费级显卡。显然的是，无法读取进模型。因此，模型的部署是一个挑战性的任务。

## 2.模型部署

本次课程使用的模型框架是lmdeploy。

### 2.1 具体步骤

使用 TurboMind 推理模型需要先将模型转化为 TurboMind 的格式，目前支持在线转换和离线转换两种形式。在线转换可以直接加载 Huggingface 模型，离线转换需需要先保存模型再加载。

TurboMind 是一款关于 LLM 推理的高效推理引擎，基于英伟达的 FasterTransformer 研发而成。它的主要功能包括：LLaMa 结构模型的支持，persistent batch 推理模式和可扩展的 KV 缓存管理器。