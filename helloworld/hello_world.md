# è½»æ¾ç©è½¬ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹è¶£å‘³ Demo

![alt text](images/logo.jpg)

## ç›®å½•

+ 1 **è¶£å‘³ Demo ä»»åŠ¡åˆ—è¡¨**
+ 2 **å®æˆ˜ï¼šé€šè¿‡ `Modelscope` å¹³å°ï¼Œä¸‹è½½ `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œ `Demo` éƒ¨ç½²**
    + 2.1 **åˆæ­¥ä»‹ç» Huggingface å¹³å°**
    + 2.2 **é…ç½®åŸºç¡€ç¯å¢ƒ**
    + 2.3 **è¿è¡Œ `InternLM2-Chat-1.8B` æ¨¡å‹çš„ `cli_demo.py`**
+ 3 **å®æˆ˜ï¼šé€šè¿‡ `OpenXLab` éƒ¨ç½²å®æˆ˜è¥ä¼˜ç§€ä½œå“ `å…«æˆ’-Chat-1.8B` æ¨¡å‹**
    + 3.1 **ç®€å•ä»‹ç» `å…«æˆ’-Chat-1.8B`ã€`Chat-å¬›å¬›-1.8B`ã€`Mini-Horo-å·§è€³`**
    + 3.2 **é…ç½®åŸºç¡€ç¯å¢ƒ**
    + 3.3 **ä½¿ç”¨ `OpenXLab` ä¸‹è½½è¿è¡Œ `å…«æˆ’-Chat Demo`**
+ 4 **å®æˆ˜ï¼šé€šè¿‡ `InternLM2-Chat-7B` è¿è¡Œ `Lagent` æ™ºèƒ½ä½“ `Demo`**
    + 4.1 **åˆæ­¥ä»‹ç» `Lagent` ç›¸å…³çŸ¥è¯†**
    + 4.2 **é…ç½®åŸºç¡€ç¯å¢ƒ**
    + 4.3 **ä½¿ç”¨ `Lagent` è¿è¡Œ `InternLM2-Chat-7B` æ¨¡å‹ä¸ºå†…æ ¸çš„æ™ºèƒ½ä½“**
+ 5 **å®æˆ˜ï¼šå®è·µéƒ¨ç½² `InternLM-XComposer2-7B` æ¨¡å‹**
    + 5.1 **åˆæ­¥ä»‹ç» `XComposer` ç›¸å…³çŸ¥è¯†**
    + 5.2 **é…ç½®åŸºç¡€ç¯å¢ƒ**
    + 5.3 **å®ç° `æµ¦è¯­Â·çµç¬”2` å›¾æ–‡ç†è§£åˆ›ä½œ `Demo`**
+ 6 **é™„å½•**
    + 6.1 **ï¼ˆå¯é€‰å‚è€ƒï¼‰ä»‹ç» `pip` æ¢æºåŠ `conda` æ¢æºæ–¹æ³•**

## 1 **è¶£å‘³ Demo ä»»åŠ¡åˆ—è¡¨**

æœ¬èŠ‚è¯¾å¯ä»¥è®©åŒå­¦ä»¬å®è·µ 4 ä¸ªä¸»è¦å†…å®¹ï¼Œåˆ†åˆ«æ˜¯ï¼š

- **é€šè¿‡ `Modelscope` å¹³å°ï¼Œä¸‹è½½ `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œ `Demo` éƒ¨ç½²**
- **é€šè¿‡ `OpenXLab` éƒ¨ç½²å®æˆ˜è¥ä¼˜ç§€ä½œå“ `å…«æˆ’-Chat-1.8B` æ¨¡å‹**
- **é€šè¿‡ `InternLM2-Chat-7B` è¿è¡Œ `Lagent` æ™ºèƒ½ä½“ `Demo`**
- **å®è·µéƒ¨ç½² `InternLM-XComposer2-7B` æ¨¡å‹**

å®æˆ˜è¥ä½œä¸šè¢«æ”¾ç½®äº `homework` æ–‡æ¡£ï¼Œå®Œæˆè¯¾ç¨‹åŸºç¡€ä½œä¸šå¯ä»¥åœ¨åç»­å­¦ä¹ ä¸­è·å¾—å‡çº§ç®—åŠ›çš„æœºä¼šå“¦ï¼

## 2 **å®æˆ˜ï¼šé€šè¿‡ `Modelscope` å¹³å°ï¼Œä¸‹è½½ `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œ `Demo` éƒ¨ç½²**

### **2.1 åˆæ­¥ä»‹ç» Huggingface å¹³å°**

`Modelscope` æ˜¯ä¸€ä¸ªå¼€æºå¹³å°ã€‚è¯¥å¹³å°æä¾›äº†ä¸€ä¸ªå…¨é¢çš„åº“ï¼Œå…¶ä¸­åŒ…æ‹¬è®¸å¤šé¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œå¦‚ BERTã€RoBERTaã€GPT-2 ç­‰ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ç”¨äºå„ç§ NLP ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€é—®ç­”ç³»ç»Ÿç­‰ã€‚

### **2.2 é…ç½®åŸºç¡€ç¯å¢ƒ**
é¦–å…ˆï¼Œæ‰“å¼€ `InternLM Studio` ç•Œé¢ï¼Œç‚¹å‡» åˆ›å»ºå¼€å‘æœº é…ç½®å¼€å‘æœºç³»ç»Ÿã€‚

![alt text](images/img-1.png)

å¡«å†™ `å¼€å‘æœºåç§°` åï¼Œç‚¹å‡» é€‰æ‹©é•œåƒ ä½¿ç”¨ `Cuda11.7-conda` é•œåƒï¼Œç„¶ååœ¨èµ„æºé…ç½®ä¸­ï¼Œä½¿ç”¨ `10% A100 * 1` çš„é€‰é¡¹ï¼Œç„¶åç«‹å³åˆ›å»ºå¼€å‘æœºå™¨ã€‚

![alt text](images/img-2.png)

ç‚¹å‡» `è¿›å…¥å¼€å‘æœº` é€‰é¡¹ã€‚

![alt text](images/img-3.png)

è¿›å…¥å¼€å‘æœºåï¼Œåœ¨ `terminal` ä¸­è¾“å…¥ç¯å¢ƒé…ç½®å‘½ä»¤ï¼š

    studio-conda -o internlm-base -t demo

é…ç½®å®Œæˆåï¼Œè¿›å…¥åˆ°æ–°åˆ›å»ºçš„ conda ç¯å¢ƒä¹‹ä¸­ï¼š

    conda activate demo

è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼Œå®Œæˆç¯å¢ƒåŒ…çš„å®‰è£…ï¼š

    pip install huggingface-hub==0.17.3
    pip install transformers==4.34 
    pip install psutil==5.9.8
    pip install accelerate==0.24.1
    pip install streamlit==1.32.2 
    pip install matplotlib==3.8.3 
    pip install modelscope==1.9.5

### **2.3 åˆ©ç”¨ Modelscope ä»£ç è¿è¡Œ InternLM2-Chat-1.8B æ¨¡å‹çš„ Cli demo**
  
æŒ‰è·¯å¾„åˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå¹¶è¿›å…¥åˆ°å¯¹åº”æ–‡ä»¶ç›®å½•ä¸­ï¼š

    mkdir -p /root/demo
    touch /root/demo/cli_demo.py
    touch /root/demo/download_mini.py
    cd /root/demo

é€šè¿‡å·¦ä¾§æ–‡ä»¶å¤¹æ ç›®ï¼ŒåŒå‡»è¿›å…¥ `demo` æ–‡ä»¶å¤¹ã€‚

![alt text](images/img-4.png)

åŒå‡»æ‰“å¼€ download_mini.py æ–‡ä»¶ï¼Œå¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š

    import os
    from modelscope.hub.snapshot_download import snapshot_download

    # åˆ›å»ºä¿å­˜æ¨¡å‹ç›®å½•
    os.system("mkdir /root/demo/internlm2-chat-1_8b")

    # save_diræ˜¯æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„ç›®å½•
    save_dir="/root/demo/internlm2-chat-1_8b"
    snapshot_download("Shanghai_AI_Laboratory/internlm2-chat-1_8b", 
                    cache_dir=save_dir, 
                    revision='v1.1.0')

æ‰§è¡Œå‘½ä»¤ï¼Œä¸‹è½½æ¨¡å‹å‚æ•°æ–‡ä»¶ï¼š

    python download_mini.py

åŒå‡»æ‰“å¼€ `download_mini.py` æ–‡ä»¶ï¼Œå¤åˆ¶ä»¥ä¸‹ä»£ç ï¼ˆå¯é€‰ï¼‰ï¼š

    import os
    from modelscope.hub.snapshot_download import snapshot_download

    # åˆ›å»ºä¿å­˜æ¨¡å‹ç›®å½•
    os.system("mkdir /root/demo/internlm2-chat-1_8b")

    # save_diræ˜¯æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„ç›®å½•
    save_dir="/root/demo/internlm2-chat-1_8b"
    snapshot_download("Shanghai_AI_Laboratory/internlm2-chat-1_8b", 
                    cache_dir=save_dir, 
                    revision='v1.1.0')

åŒå‡»æ‰“å¼€ `cli_demo.py` æ–‡ä»¶ã€‚å°† `github repo` ä¸­çš„å¯¹åº”ä»£ç å¤åˆ¶è¿›å»ï¼Œå¹¶åœ¨ `terminal` è¿è¡Œå‘½ä»¤ï¼š

    cd /root/demo
    python cli_demo.py

ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆï¼Œæ•ˆæœå¦‚ä¸‹ï¼š

![alt text](images/img-5.png)

## 3 **å®æˆ˜ï¼šé€šè¿‡ `OpenXLab` éƒ¨ç½²å®æˆ˜è¥ä¼˜ç§€ä½œå“ `å…«æˆ’-Chat-1.8B` æ¨¡å‹**

### 3.1 **ç®€å•ä»‹ç» `å…«æˆ’-Chat-1.8B`ã€`Chat-å¬›å¬›-1.8B`ã€`Mini-Horo-å·§è€³`ï¼ˆå®æˆ˜è¥ä¼˜ç§€ä½œå“ï¼‰**
`å…«æˆ’-Chat-1.8B`ã€`Chat-å¬›å¬›-1.8B`ã€`Mini-Horo-å·§è€³` å‡æ˜¯åœ¨ç¬¬ä¸€æœŸå®æˆ˜è¥ä¸­è¿ç”¨ `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œå¾®è°ƒè®­ç»ƒçš„ä¼˜ç§€æˆæœã€‚å…¶ä¸­ï¼Œ`å…«æˆ’-Chat-1.8B` æ˜¯åˆ©ç”¨ã€Šè¥¿æ¸¸è®°ã€‹å‰§æœ¬ä¸­æ‰€æœ‰å…³äºçŒªå…«æˆ’çš„å°è¯å’Œè¯­å¥ä»¥åŠ LLM API ç”Ÿæˆçš„ç›¸å…³æ•°æ®ç»“æœï¼Œè¿›è¡Œå…¨é‡å¾®è°ƒå¾—åˆ°çš„çŒªå…«æˆ’èŠå¤©æ¨¡å‹ã€‚ä½œä¸º `Roleplay-with-XiYou` å­é¡¹ç›®ä¹‹ä¸€ï¼Œ`å…«æˆ’-Chat-1.8B` èƒ½å¤Ÿä»¥è¾ƒä½çš„è®­ç»ƒæˆæœ¬è¾¾åˆ°ä¸é”™çš„è§’è‰²æ¨¡ä»¿èƒ½åŠ›ï¼ŒåŒæ—¶ä½éƒ¨ç½²æ¡ä»¶èƒ½å¤Ÿä¸ºåç»­å·¥ä½œé™ä½ç®—åŠ›é—¨æ§›ã€‚

<center>

![alt text](images/img-6.png)

</center>

ç»“åˆå®æˆ˜ç« èŠ‚ 2 çš„ç»éªŒï¼Œæˆ‘ä»¬é‡‡ç”¨ `OpenXLab` å¹³å°å®Œæˆ `å…«æˆ’-Chat-1.8B` çš„éƒ¨ç½²ã€‚`OpenXLab` å¹³å°æ˜¯é¢å‘ AI ç ”ç©¶å‘˜å’Œå¼€å‘è€…æä¾› AI é¢†åŸŸçš„ä¸€ç«™å¼æœåŠ¡å¹³å°ï¼ŒåŒ…å«æ•°æ®é›†ä¸­å¿ƒã€æ¨¡å‹ä¸­å¿ƒå’Œåº”ç”¨ä¸­å¿ƒã€‚å…·ä½“ç»†èŠ‚å’Œå„ç§ç‚«é…·çš„åº”ç”¨æ–¹æ³•ä¼šåœ¨å®æˆ˜è¥åç»­ç« èŠ‚è¯¦ç»†è¯´æ˜ã€‚

<center>

![alt text](images/img-7.png)

</center>

å½“ç„¶ï¼ŒåŒå­¦ä»¬ä¹Ÿå¯ä»¥å‚è€ƒå…¶ä»–ä¼˜ç§€çš„å®æˆ˜è¥é¡¹ç›®ï¼Œå…·ä½“æ¨¡å‹é“¾æ¥å¦‚ä¸‹ï¼š

+ **å…«æˆ’-Chat-1.8Bï¼šhttps://openxlab.org.cn/models/detail/JimmyMa99/BaJie-Chat-1.8b**
+ **Chat-å¬›å¬›-1.8Bï¼šhttps://openxlab.org.cn/models/detail/BYCJS/huanhuan-chat-internlm2-1_8b**
+ **Mini-Horo-å·§è€³ï¼šhttps://openxlab.org.cn/models/detail/SaaRaaS/Horowag_Mini**

ğŸé‚£ä¹ˆï¼Œå¼€å§‹å®éªŒï¼ï¼ï¼

### 3.2 **é…ç½®åŸºç¡€ç¯å¢ƒ**

åˆ›å»ºç”¨äºæ¼”ç¤ºçš„æ–‡ä»¶ï¼Œè¾“å…¥ä»¥ä¸‹æŒ‡ä»¤ï¼š

    mkdir -p /root/demo/work
    touch /root/demo/work/bajie_download.py
    touch /root/demo/work/bajie_chat.py
    cd /root/demo/work

è¿è¡Œç¯å¢ƒè¡¥å……å‘½ä»¤ï¼š

    conda activate demo

### 3.3 **ä½¿ç”¨ `OpenXLab` ä¸‹è½½è¿è¡Œ Chat-å…«æˆ’ Demo**

åœ¨ `Web IDE` ä¸­æ‰“å¼€ `download.py`ï¼š

![alt text](images/img-8.png)

å¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š

    import torch
    import os
    from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel
    base_path = './BaJie-Chat-1_8b'
    os.system('apt install git')
    os.system('apt install git-lfs')
    os.system(f'git clone https://code.openxlab.org.cn/JimmyMa99/BaJie-Chat-1.8b.git {base_path}')
    os.system(f'cd {base_path} && git lfs pull')

    model_path = '/root/demo/work/BaJie-Chat-1_8b'
    tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_path,trust_remote_code=True, torch_dtype=torch.float16).cuda()

è¿è¡Œè¯¥ python æ–‡ä»¶ï¼Œè¾“å…¥ä»¥ä¸‹æŒ‡ä»¤ï¼š

    python bajie_download.py

æ‰“å¼€ `bajie_chat.py` æ–‡ä»¶åï¼Œå°† github ä»“åº“ä¸­å¯¹åº”çš„ä»£ç å¤åˆ¶è¿›å»ï¼Œè¾“å…¥è¿è¡Œå‘½ä»¤ï¼š

    streamlit run /root/demo/work/bajie_chat.py --server.address 127.0.0.1 --server.port 6006

å¾…ç¨‹åºè¿è¡Œçš„åŒæ—¶ï¼Œå¯¹æœ¬åœ°ç«¯å£ç¯å¢ƒé…ç½®æœ¬åœ° `PowerShell` ã€‚ä½¿ç”¨å¿«æ·é”®ç»„åˆ `Windows + R`ï¼ˆ Windows å³å¼€å§‹èœå•é”® ï¼‰æ‰“å¼€æŒ‡ä»¤ç•Œé¢ï¼Œå¹¶è¾“å…¥å‘½ä»¤ `powershell` æŒ‰ä¸‹å›è½¦é”®ã€‚

![alt text](images/img-9.png)

æ‰“å¼€ PowerShell åï¼Œå…ˆæŸ¥è¯¢ç«¯å£ï¼Œå†æ ¹æ®ç«¯å£é”®å…¥å‘½ä»¤ ï¼ˆä¾‹å¦‚å›¾ä¸­ç«¯å£ç¤ºä¾‹ä¸º 38374ï¼‰ï¼š

![alt text](images/img-A.png)

    ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 38374

å†å¤åˆ¶ä¸‹æ–¹çš„å¯†ç ï¼Œè¾“å…¥åˆ° `password` ä¸­ï¼Œç›´æ¥å›è½¦ï¼š

![alt text](images/img-B.png)

æœ€ç»ˆä¿æŒåœ¨å¦‚ä¸‹æ•ˆæœå³å¯ï¼š

![alt text](images/img-C.png)

æ‰“å¼€ç½‘é¡µåï¼Œç­‰å¾…åŠ è½½å®Œæˆå³å¯è¿›è¡Œå¯¹è¯ï¼Œè‡³æ­¤ï¼Œæœ¬ç« å®æˆ˜ç¯èŠ‚ç»“æŸï¼Œæ•ˆæœå›¾å¦‚ä¸‹ï¼š

![alt text](images/img-D.png)

4. å®æˆ˜ï¼šé€šè¿‡ InternLM Studio å†…éƒ¨çš„ share ç©ºé—´ï¼Œ