<div align="center">

![alt text](images/logo.jpg)

</div>

# è½»æ¾ç©è½¬ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹è¶£å‘³ Demo

## 1 **è¶£å‘³ Demo ä»»åŠ¡åˆ—è¡¨**

æœ¬èŠ‚è¯¾å¯ä»¥è®©åŒå­¦ä»¬å®è·µ 4 ä¸ªä¸»è¦å†…å®¹ï¼Œåˆ†åˆ«æ˜¯ï¼š

- **éƒ¨ç½² `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¯¹è¯**
- **éƒ¨ç½²å®æˆ˜è¥ä¼˜ç§€ä½œå“ `å…«æˆ’-Chat-1.8B` æ¨¡å‹**
- **é€šè¿‡ `InternLM2-Chat-7B` è¿è¡Œ `Lagent` æ™ºèƒ½ä½“ `Demo`**
- **å®è·µéƒ¨ç½² `æµ¦è¯­Â·çµç¬”2` æ¨¡å‹**

## 2 **éƒ¨ç½² `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¯¹è¯**

### **2.1 é…ç½®åŸºç¡€ç¯å¢ƒ**
é¦–å…ˆï¼Œæ‰“å¼€ `Intern Studio` ç•Œé¢ï¼Œç‚¹å‡» åˆ›å»ºå¼€å‘æœº é…ç½®å¼€å‘æœºç³»ç»Ÿã€‚

![alt text](images/img-1.png)

å¡«å†™ `å¼€å‘æœºåç§°` åï¼Œç‚¹å‡» é€‰æ‹©é•œåƒ ä½¿ç”¨ `Cuda11.7-conda` é•œåƒï¼Œç„¶ååœ¨èµ„æºé…ç½®ä¸­ï¼Œä½¿ç”¨ `10% A100 * 1` çš„é€‰é¡¹ï¼Œç„¶åç«‹å³åˆ›å»ºå¼€å‘æœºå™¨ã€‚

![alt text](images/img-2.png)

ç‚¹å‡» `è¿›å…¥å¼€å‘æœº` é€‰é¡¹ã€‚

![alt text](images/img-3.png)

**è¿›å…¥å¼€å‘æœºåï¼Œåœ¨ `terminal` ä¸­è¾“å…¥ç¯å¢ƒé…ç½®å‘½ä»¤ (é…ç½®ç¯å¢ƒæ—¶é—´è¾ƒé•¿ï¼Œéœ€è€å¿ƒç­‰å¾…)ï¼š**

```bash
studio-conda -o internlm-base -t demo
# ä¸ studio-conda ç­‰æ•ˆçš„é…ç½®æ–¹æ¡ˆ
# conda create -n demo python==3.10 -y
# conda activate demo
# conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia
```

![alt text](images/check-1.png)

![alt text](images/check-2.png)

é…ç½®å®Œæˆåï¼Œè¿›å…¥åˆ°æ–°åˆ›å»ºçš„ `conda` ç¯å¢ƒä¹‹ä¸­ï¼š

```bash
conda activate demo
```

è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼Œå®Œæˆç¯å¢ƒåŒ…çš„å®‰è£…ï¼š

```bash
pip install huggingface-hub==0.17.3
pip install transformers==4.34 
pip install psutil==5.9.8
pip install accelerate==0.24.1
pip install streamlit==1.32.2 
pip install matplotlib==3.8.3 
pip install modelscope==1.9.5
pip install sentencepiece==0.1.99
```

### **2.2 ä¸‹è½½ `InternLM2-Chat-1.8B` æ¨¡å‹**
  
æŒ‰è·¯å¾„åˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå¹¶è¿›å…¥åˆ°å¯¹åº”æ–‡ä»¶ç›®å½•ä¸­ï¼š

```bash
mkdir -p /root/demo
touch /root/demo/cli_demo.py
touch /root/demo/download_mini.py
cd /root/demo
```

é€šè¿‡å·¦ä¾§æ–‡ä»¶å¤¹æ ç›®ï¼ŒåŒå‡»è¿›å…¥ `demo` æ–‡ä»¶å¤¹ã€‚

![alt text](images/img-4.png)

åŒå‡»æ‰“å¼€ `/root/demo/download_mini.py` æ–‡ä»¶ï¼Œå¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š

```python
import os
from modelscope.hub.snapshot_download import snapshot_download

# åˆ›å»ºä¿å­˜æ¨¡å‹ç›®å½•
os.system("mkdir /root/models")

# save_diræ˜¯æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„ç›®å½•
save_dir="/root/models"

snapshot_download("Shanghai_AI_Laboratory/internlm2-chat-1_8b", 
                  cache_dir=save_dir, 
                  revision='v1.1.0')

```

æ‰§è¡Œå‘½ä»¤ï¼Œä¸‹è½½æ¨¡å‹å‚æ•°æ–‡ä»¶ï¼š

```bash
python /root/demo/download_mini.py
```

### **2.3 è¿è¡Œ cli_demo**

åŒå‡»æ‰“å¼€ `/root/demo/cli_demo.py` æ–‡ä»¶ï¼Œå¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM


model_name_or_path = "/root/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b"

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='cuda:0')
model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='cuda:0')
model = model.eval()

system_prompt = """You are an AI assistant whose name is InternLM (ä¹¦ç”ŸÂ·æµ¦è¯­).
- InternLM (ä¹¦ç”ŸÂ·æµ¦è¯­) is a conversational language model that is developed by Shanghai AI Laboratory (ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤). It is designed to be helpful, honest, and harmless.
- InternLM (ä¹¦ç”ŸÂ·æµ¦è¯­) can understand and communicate fluently in the language chosen by the user such as English and ä¸­æ–‡.
"""

messages = [(system_prompt, '')]

print("=============Welcome to InternLM chatbot, type 'exit' to exit.=============")

while True:
    input_text = input("\nUser  >>> ")
    input_text = input_text.replace(' ', '')
    if input_text == "exit":
        break

    length = 0
    for response, _ in model.stream_chat(tokenizer, input_text, messages):
        if response is not None:
            print(response[length:], flush=True, end="")
            length = len(response)

```

è¾“å…¥å‘½ä»¤ï¼Œæ‰§è¡Œ Demo ç¨‹åºï¼š

```bash
conda activate demo
python /root/demo/cli_demo.py
```

ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆï¼Œé”®å…¥å†…å®¹ç¤ºä¾‹ï¼š

    è¯·åˆ›ä½œä¸€ä¸ª 300 å­—çš„å°æ•…äº‹

æ•ˆæœå¦‚ä¸‹ï¼š

![alt text](images/img-5.png)

## 3 **å®æˆ˜ï¼šéƒ¨ç½²å®æˆ˜è¥ä¼˜ç§€ä½œå“ `å…«æˆ’-Chat-1.8B` æ¨¡å‹**

### 3.1 **ç®€å•ä»‹ç» `å…«æˆ’-Chat-1.8B`ã€`Chat-å¬›å¬›-1.8B`ã€`Mini-Horo-å·§è€³`ï¼ˆå®æˆ˜è¥ä¼˜ç§€ä½œå“ï¼‰**
`å…«æˆ’-Chat-1.8B`ã€`Chat-å¬›å¬›-1.8B`ã€`Mini-Horo-å·§è€³` å‡æ˜¯åœ¨ç¬¬ä¸€æœŸå®æˆ˜è¥ä¸­è¿ç”¨ `InternLM2-Chat-1.8B` æ¨¡å‹è¿›è¡Œå¾®è°ƒè®­ç»ƒçš„ä¼˜ç§€æˆæœã€‚å…¶ä¸­ï¼Œ`å…«æˆ’-Chat-1.8B` æ˜¯åˆ©ç”¨ã€Šè¥¿æ¸¸è®°ã€‹å‰§æœ¬ä¸­æ‰€æœ‰å…³äºçŒªå…«æˆ’çš„å°è¯å’Œè¯­å¥ä»¥åŠ LLM API ç”Ÿæˆçš„ç›¸å…³æ•°æ®ç»“æœï¼Œè¿›è¡Œå…¨é‡å¾®è°ƒå¾—åˆ°çš„çŒªå…«æˆ’èŠå¤©æ¨¡å‹ã€‚ä½œä¸º `Roleplay-with-XiYou` å­é¡¹ç›®ä¹‹ä¸€ï¼Œ`å…«æˆ’-Chat-1.8B` èƒ½å¤Ÿä»¥è¾ƒä½çš„è®­ç»ƒæˆæœ¬è¾¾åˆ°ä¸é”™çš„è§’è‰²æ¨¡ä»¿èƒ½åŠ›ï¼ŒåŒæ—¶ä½éƒ¨ç½²æ¡ä»¶èƒ½å¤Ÿä¸ºåç»­å·¥ä½œé™ä½ç®—åŠ›é—¨æ§›ã€‚

<div align="center">

![alt text](images/img-6.png)

</div>

å½“ç„¶ï¼ŒåŒå­¦ä»¬ä¹Ÿå¯ä»¥å‚è€ƒå…¶ä»–ä¼˜ç§€çš„å®æˆ˜è¥é¡¹ç›®ï¼Œå…·ä½“æ¨¡å‹é“¾æ¥å¦‚ä¸‹ï¼š

+ **å…«æˆ’-Chat-1.8Bï¼šhttps://www.modelscope.cn/models/JimmyMa99/BaJie-Chat-mini/summary**
+ **Chat-å¬›å¬›-1.8Bï¼šhttps://openxlab.org.cn/models/detail/BYCJS/huanhuan-chat-internlm2-1_8b**
+ **Mini-Horo-å·§è€³ï¼šhttps://openxlab.org.cn/models/detail/SaaRaaS/Horowag_Mini**

ğŸé‚£ä¹ˆï¼Œå¼€å§‹å®éªŒï¼ï¼ï¼

### 3.2 **é…ç½®åŸºç¡€ç¯å¢ƒ**

è¿è¡Œç¯å¢ƒå‘½ä»¤ï¼š

```bash
conda activate demo
```

ä½¿ç”¨ `git` å‘½ä»¤æ¥è·å¾—ä»“åº“å†…çš„ Demo æ–‡ä»¶ï¼š
```bash
cd /root/
git clone https://gitee.com/InternLM/Tutorial -b camp2
# git clone https://github.com/InternLM/Tutorial -b camp2
cd /root/Tutorial
```

### 3.3 **ä¸‹è½½è¿è¡Œ Chat-å…«æˆ’ Demo**

åœ¨ `Web IDE` ä¸­æ‰§è¡Œ `bajie_download.py`ï¼š

```bash
python /root/Tutorial/helloworld/bajie_download.py
```

å¾…ç¨‹åºä¸‹è½½å®Œæˆåï¼Œè¾“å…¥è¿è¡Œå‘½ä»¤ï¼š

```bash
streamlit run /root/Tutorial/helloworld/bajie_chat.py --server.address 127.0.0.1 --server.port 6006
```

å¾…ç¨‹åºè¿è¡Œçš„åŒæ—¶ï¼Œå¯¹ç«¯å£ç¯å¢ƒé…ç½®æœ¬åœ° `PowerShell` ã€‚ä½¿ç”¨å¿«æ·é”®ç»„åˆ `Windows + R`ï¼ˆWindows å³å¼€å§‹èœå•é”®ï¼‰æ‰“å¼€æŒ‡ä»¤ç•Œé¢ï¼Œå¹¶è¾“å…¥å‘½ä»¤ï¼ŒæŒ‰ä¸‹å›è½¦é”®ã€‚ï¼ˆMac ç”¨æˆ·æ‰“å¼€ç»ˆç«¯å³å¯ï¼‰

![alt text](images/img-8.png)

æ‰“å¼€ PowerShell åï¼Œå…ˆæŸ¥è¯¢ç«¯å£ï¼Œå†æ ¹æ®ç«¯å£é”®å…¥å‘½ä»¤ ï¼ˆä¾‹å¦‚å›¾ä¸­ç«¯å£ç¤ºä¾‹ä¸º 38374ï¼‰ï¼š

![alt text](images/img-A.png)

```bash
# ä»æœ¬åœ°ä½¿ç”¨ ssh è¿æ¥ studio ç«¯å£
# å°†ä¸‹æ–¹ç«¯å£å· 38374 æ›¿æ¢æˆè‡ªå·±çš„ç«¯å£å·
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 38374
```

å†å¤åˆ¶ä¸‹æ–¹çš„å¯†ç ï¼Œè¾“å…¥åˆ° `password` ä¸­ï¼Œç›´æ¥å›è½¦ï¼š

![alt text](images/img-B.png)

æœ€ç»ˆä¿æŒåœ¨å¦‚ä¸‹æ•ˆæœå³å¯ï¼š

![alt text](images/img-C.png)

æ‰“å¼€ [http://127.0.0.1:6006](http://127.0.0.1:6006) åï¼Œç­‰å¾…åŠ è½½å®Œæˆå³å¯è¿›è¡Œå¯¹è¯ï¼Œé”®å…¥å†…å®¹ç¤ºä¾‹å¦‚ä¸‹ï¼š

    ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»

æ•ˆæœå›¾å¦‚ä¸‹ï¼š

![alt text](images/img-D.png)

##  4 **å®æˆ˜ï¼šä½¿ç”¨ `Lagent` è¿è¡Œ `InternLM2-Chat-7B` æ¨¡å‹ï¼ˆå¼€å¯ 30% A100 æƒé™åæ‰å¯å¼€å¯æ­¤ç« èŠ‚ï¼‰**

### 4.1 **åˆæ­¥ä»‹ç» Lagent ç›¸å…³çŸ¥è¯†**
Lagent æ˜¯ä¸€ä¸ªè½»é‡çº§ã€å¼€æºçš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“ï¼ˆagentï¼‰æ¡†æ¶ï¼Œæ”¯æŒç”¨æˆ·å¿«é€Ÿåœ°å°†ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹è½¬å˜ä¸ºå¤šç§ç±»å‹çš„æ™ºèƒ½ä½“ï¼Œå¹¶æä¾›äº†ä¸€äº›å…¸å‹å·¥å…·ä¸ºå¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½ã€‚å®ƒçš„æ•´ä¸ªæ¡†æ¶å›¾å¦‚ä¸‹:

![alt text](images/Lagent-1.png)

Lagent çš„ç‰¹æ€§æ€»ç»“å¦‚ä¸‹ï¼š
- æµå¼è¾“å‡ºï¼šæä¾› stream_chat æ¥å£ä½œæµå¼è¾“å‡ºï¼Œæœ¬åœ°å°±èƒ½æ¼”ç¤ºé…·ç‚«çš„æµå¼ Demoã€‚
- æ¥å£ç»Ÿä¸€ï¼Œè®¾è®¡å…¨é¢å‡çº§ï¼Œæå‡æ‹“å±•æ€§ï¼ŒåŒ…æ‹¬ï¼š  
    - Model : ä¸è®ºæ˜¯ OpenAI API, Transformers è¿˜æ˜¯æ¨ç†åŠ é€Ÿæ¡†æ¶ LMDeploy ä¸€ç½‘æ‰“å°½ï¼Œæ¨¡å‹åˆ‡æ¢å¯ä»¥æ¸¸åˆƒæœ‰ä½™ï¼›         
    - Action: ç®€å•çš„ç»§æ‰¿å’Œè£…é¥°ï¼Œå³å¯æ‰“é€ è‡ªå·±ä¸ªäººçš„å·¥å…·é›†ï¼Œä¸è®º InternLM è¿˜æ˜¯ GPT å‡å¯é€‚é…ï¼›        
    - Agentï¼šä¸ Model çš„è¾“å…¥æ¥å£ä¿æŒä¸€è‡´ï¼Œæ¨¡å‹åˆ°æ™ºèƒ½ä½“çš„èœ•å˜åªéœ€ä¸€æ­¥ï¼Œä¾¿æ·å„ç§ agent çš„æ¢ç´¢å®ç°ï¼›  
- æ–‡æ¡£å…¨é¢å‡çº§ï¼ŒAPI æ–‡æ¡£å…¨è¦†ç›–ã€‚

### 4.2 **é…ç½®åŸºç¡€ç¯å¢ƒï¼ˆå¼€å¯ 30% A100 æƒé™åæ‰å¯å¼€å¯æ­¤ç« èŠ‚ï¼‰**

æ‰“å¼€ `Intern Studio` ç•Œé¢ï¼Œè°ƒèŠ‚é…ç½®ï¼ˆå¿…é¡»åœ¨å¼€å‘æœºå…³é—­çš„æ¡ä»¶ä¸‹è¿›è¡Œï¼‰ï¼š

![alt text](images/img-E.png)

é‡æ–°å¼€å¯å¼€å‘æœºï¼Œè¾“å…¥å‘½ä»¤ï¼Œå¼€å¯ conda ç¯å¢ƒï¼š

```bash
conda activate demo
```

æ‰“å¼€æ–‡ä»¶å­è·¯å¾„

```bash
cd /root/demo
```

ä½¿ç”¨ git å‘½ä»¤ä¸‹è½½ Lagent ç›¸å…³çš„ä»£ç åº“ï¼š

```bash
git clone https://gitee.com/internlm/lagent.git
# git clone https://github.com/internlm/lagent.git
cd /root/demo/lagent
git checkout 581d9fb8987a5d9b72bb9ebd37a95efd47d479ac
pip install -e . # æºç å®‰è£…
```

è¿è¡Œæ•ˆæœå¦‚å›¾ï¼š

![alt text](images/img-F.png)

### 4.3 **ä½¿ç”¨ `Lagent` è¿è¡Œ `InternLM2-Chat-7B` æ¨¡å‹ä¸ºå†…æ ¸çš„æ™ºèƒ½ä½“**

`Intern Studio` åœ¨ share æ–‡ä»¶ä¸­é¢„ç•™äº†å®è·µç« èŠ‚æ‰€éœ€è¦çš„æ‰€æœ‰åŸºç¡€æ¨¡å‹ï¼ŒåŒ…æ‹¬ `InternLM2-Chat-7b` ã€`InternLM2-Chat-1.8b` ç­‰ç­‰ã€‚æˆ‘ä»¬å¯ä»¥åœ¨åæœŸä»»åŠ¡ä¸­ä½¿ç”¨ `share` æ–‡æ¡£ä¸­åŒ…å«çš„èµ„æºï¼Œä½†æ˜¯åœ¨æœ¬ç« èŠ‚ï¼Œä¸ºäº†èƒ½è®©å¤§å®¶äº†è§£å„ç±»å¹³å°ä½¿ç”¨æ–¹æ³•ï¼Œè¿˜æ˜¯æ¨èåŒå­¦ä»¬æŒ‰ç…§æç¤ºæ­¥éª¤è¿›è¡Œå®éªŒã€‚

![alt text](images/img-G.png)

æ‰“å¼€ lagent è·¯å¾„ï¼š

```bash
cd /root/demo/lagent
```

åœ¨ terminal ä¸­è¾“å…¥æŒ‡ä»¤ï¼Œæ„é€ è½¯é“¾æ¥å¿«æ·è®¿é—®æ–¹å¼ï¼š

```bash
ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b /root/models/internlm2-chat-7b
```

æ‰“å¼€ `lagent` è·¯å¾„ä¸‹ `examples/internlm2_agent_web_demo_hf.py` æ–‡ä»¶ï¼Œå¹¶ä¿®æ”¹å¯¹åº”ä½ç½® (71è¡Œå·¦å³) ä»£ç ï¼š

![alt text](images/img-H.png)

```bash
# å…¶ä»–ä»£ç ...
value='/root/models/internlm2-chat-7b'
# å…¶ä»–ä»£ç ...
```

è¾“å…¥è¿è¡Œå‘½ä»¤ - **ç‚¹å¼€ 6006 é“¾æ¥åï¼Œå¤§çº¦éœ€è¦ 5 åˆ†é’Ÿå®Œæˆæ¨¡å‹åŠ è½½ï¼š**

```bash
streamlit run /root/demo/lagent/examples/internlm2_agent_web_demo_hf.py --server.address 127.0.0.1 --server.port 6006
```

å¾…ç¨‹åºè¿è¡Œçš„åŒæ—¶ï¼Œå¯¹æœ¬åœ°ç«¯å£ç¯å¢ƒé…ç½®æœ¬åœ° `PowerShell` ã€‚ä½¿ç”¨å¿«æ·é”®ç»„åˆ `Windows + R`ï¼ˆWindows å³å¼€å§‹èœå•é”®ï¼‰æ‰“å¼€æŒ‡ä»¤ç•Œé¢ï¼Œå¹¶è¾“å…¥å‘½ä»¤ï¼ŒæŒ‰ä¸‹å›è½¦é”®ã€‚ï¼ˆMac ç”¨æˆ·æ‰“å¼€ç»ˆç«¯å³å¯ï¼‰

![alt text](images/img-8.png)

æ‰“å¼€ PowerShell åï¼Œå…ˆæŸ¥è¯¢ç«¯å£ï¼Œå†æ ¹æ®ç«¯å£é”®å…¥å‘½ä»¤ ï¼ˆä¾‹å¦‚å›¾ä¸­ç«¯å£ç¤ºä¾‹ä¸º 38374ï¼‰ï¼š

![alt text](images/img-A.png)

```bash
# ä»æœ¬åœ°ä½¿ç”¨ ssh è¿æ¥ studio ç«¯å£
# å°†ä¸‹æ–¹ç«¯å£å· 38374 æ›¿æ¢æˆè‡ªå·±çš„ç«¯å£å·
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 38374
```

å†å¤åˆ¶ä¸‹æ–¹çš„å¯†ç ï¼Œè¾“å…¥åˆ° `password` ä¸­ï¼Œç›´æ¥å›è½¦ï¼š

![alt text](images/img-B.png)

æœ€ç»ˆä¿æŒåœ¨å¦‚ä¸‹æ•ˆæœå³å¯ï¼š

![alt text](images/img-C.png)

æ‰“å¼€ [http://127.0.0.1:6006](http://127.0.0.1:6006) åï¼Œï¼ˆä¼šæœ‰è¾ƒé•¿çš„åŠ è½½æ—¶é—´ï¼‰å‹¾ä¸Šæ•°æ®åˆ†æï¼Œå…¶ä»–çš„é€‰é¡¹ä¸è¦é€‰æ‹©ï¼Œè¿›è¡Œè®¡ç®—æ–¹é¢çš„ Demo å¯¹è¯ï¼Œå³å®Œæˆæœ¬ç« èŠ‚å®æˆ˜ã€‚é”®å…¥å†…å®¹ç¤ºä¾‹ï¼š

    è¯·è§£æ–¹ç¨‹ 2*X=1360 ä¹‹ä¸­ X çš„ç»“æœ

![alt text](images/img-I.png)

## 5 **å®æˆ˜ï¼šå®è·µéƒ¨ç½² `æµ¦è¯­Â·çµç¬”2` æ¨¡å‹ï¼ˆå¼€å¯ 50% A100 æƒé™åæ‰å¯å¼€å¯æ­¤ç« èŠ‚ï¼‰**

### 5.1 **åˆæ­¥ä»‹ç» `XComposer2` ç›¸å…³çŸ¥è¯†**
`æµ¦è¯­Â·çµç¬”2` æ˜¯åŸºäº `ä¹¦ç”ŸÂ·æµ¦è¯­2` å¤§è¯­è¨€æ¨¡å‹ç ”å‘çš„çªç ´æ€§çš„å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå…·æœ‰éå‡¡çš„å›¾æ–‡å†™ä½œå’Œå›¾åƒç†è§£èƒ½åŠ›ï¼Œåœ¨å¤šç§åº”ç”¨åœºæ™¯è¡¨ç°å‡ºè‰²ï¼Œæ€»ç»“èµ·æ¥å…¶å…·æœ‰ï¼š
- è‡ªç”±æŒ‡ä»¤è¾“å…¥çš„å›¾æ–‡å†™ä½œèƒ½åŠ›ï¼š `æµ¦è¯­Â·çµç¬”2` å¯ä»¥ç†è§£è‡ªç”±å½¢å¼çš„å›¾æ–‡æŒ‡ä»¤è¾“å…¥ï¼ŒåŒ…æ‹¬å¤§çº²ã€æ–‡ç« ç»†èŠ‚è¦æ±‚ã€å‚è€ƒå›¾ç‰‡ç­‰ï¼Œä¸ºç”¨æˆ·æ‰“é€ å›¾æ–‡å¹¶è²Œçš„ä¸“å±æ–‡ç« ã€‚ç”Ÿæˆçš„æ–‡ç« æ–‡é‡‡æ–ç„¶ï¼Œå›¾æ–‡ç›¸å¾—ç›Šå½°ï¼Œæä¾›æ²‰æµ¸å¼çš„é˜…è¯»ä½“éªŒã€‚
- å‡†ç¡®çš„å›¾æ–‡é—®é¢˜è§£ç­”èƒ½åŠ›ï¼š`æµ¦è¯­Â·çµç¬”2` å…·æœ‰æµ·é‡å›¾æ–‡çŸ¥è¯†ï¼Œå¯ä»¥å‡†ç¡®çš„å›å¤å„ç§å›¾æ–‡é—®ç­”éš¾é¢˜ï¼Œåœ¨è¯†åˆ«ã€æ„ŸçŸ¥ã€ç»†èŠ‚æè¿°ã€è§†è§‰æ¨ç†ç­‰èƒ½åŠ›ä¸Šè¡¨ç°æƒŠäººã€‚
- æ°å‡ºçš„ç»¼åˆèƒ½åŠ›ï¼š `æµ¦è¯­Â·çµç¬”2-7B` åŸºäº `ä¹¦ç”ŸÂ·æµ¦è¯­2-7B` æ¨¡å‹ï¼Œåœ¨13é¡¹å¤šæ¨¡æ€è¯„æµ‹ä¸­å¤§å¹…é¢†å…ˆåŒé‡çº§å¤šæ¨¡æ€æ¨¡å‹ï¼Œåœ¨å…¶ä¸­6é¡¹è¯„æµ‹ä¸­è¶…è¿‡ `GPT-4V` å’Œ `Gemini Pro`ã€‚

![alt text](images/Benchmark_radar_CN.png)

### 5.2 **é…ç½®åŸºç¡€ç¯å¢ƒï¼ˆå¼€å¯ 50% A100 æƒé™åæ‰å¯å¼€å¯æ­¤ç« èŠ‚ï¼‰**

é€‰ç”¨ `50% A100` è¿›è¡Œå¼€å‘ï¼š

![alt text](images/check-4.png)

è¿›å…¥å¼€å‘æœºï¼Œå¯åŠ¨ `conda` ç¯å¢ƒï¼š

```bash
conda activate demo
# è¡¥å……ç¯å¢ƒåŒ…
pip install timm==0.4.12 sentencepiece==0.1.99 markdown2==2.4.10 xlsxwriter==3.1.2 gradio==4.13.0 modelscope==1.9.5
```

ä¸‹è½½ **InternLM-XComposer ä»“åº“** ç›¸å…³çš„ä»£ç èµ„æºï¼š

```bash
cd /root/demo
git clone https://gitee.com/internlm/InternLM-XComposer.git
# git clone https://github.com/internlm/InternLM-XComposer.git
cd /root/demo/InternLM-XComposer
git checkout f31220eddca2cf6246ee2ddf8e375a40457ff626
```

åœ¨ `terminal` ä¸­è¾“å…¥æŒ‡ä»¤ï¼Œæ„é€ è½¯é“¾æ¥å¿«æ·è®¿é—®æ–¹å¼ï¼š

```bash
ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b /root/models/internlm-xcomposer2-7b
ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b /root/models/internlm-xcomposer2-vl-7b
```

### 5.3 **å›¾æ–‡å†™ä½œå®æˆ˜ï¼ˆå¼€å¯ 50% A100 æƒé™åæ‰å¯å¼€å¯æ­¤ç« èŠ‚ï¼‰**

ç»§ç»­è¾“å…¥æŒ‡ä»¤ï¼Œç”¨äºå¯åŠ¨ `InternLM-XComposer`ï¼š

```bash
cd /root/demo/InternLM-XComposer
python /root/demo/InternLM-XComposer/examples/gradio_demo_composition.py  \
--code_path /root/models/internlm-xcomposer2-7b \
--private \
--num_gpus 1 \
--port 6006
```

å¾…ç¨‹åºè¿è¡Œçš„åŒæ—¶ï¼Œå‚è€ƒç« èŠ‚ 3.3 éƒ¨åˆ†å¯¹ç«¯å£ç¯å¢ƒé…ç½®æœ¬åœ° `PowerShell` ã€‚ä½¿ç”¨å¿«æ·é”®ç»„åˆ `Windows + R`ï¼ˆWindows å³å¼€å§‹èœå•é”®ï¼‰æ‰“å¼€æŒ‡ä»¤ç•Œé¢ï¼Œï¼ˆMac ç”¨æˆ·æ‰“å¼€ç»ˆç«¯å³å¯ï¼‰å¹¶è¾“å…¥å‘½ä»¤ï¼ŒæŒ‰ä¸‹å›è½¦é”®ï¼š

![alt text](images/img-8.png)

æ‰“å¼€ PowerShell åï¼Œå…ˆæŸ¥è¯¢ç«¯å£ï¼Œå†æ ¹æ®ç«¯å£é”®å…¥å‘½ä»¤ ï¼ˆä¾‹å¦‚å›¾ä¸­ç«¯å£ç¤ºä¾‹ä¸º 38374ï¼‰ï¼š

![alt text](images/img-A.png)

```bash
# ä»æœ¬åœ°ä½¿ç”¨ ssh è¿æ¥ studio ç«¯å£
# å°†ä¸‹æ–¹ç«¯å£å· 38374 æ›¿æ¢æˆè‡ªå·±çš„ç«¯å£å·
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 38374
```

å†å¤åˆ¶ä¸‹æ–¹çš„å¯†ç ï¼Œè¾“å…¥åˆ° `password` ä¸­ï¼Œç›´æ¥å›è½¦ï¼š

![alt text](images/img-B.png)

æœ€ç»ˆä¿æŒåœ¨å¦‚ä¸‹æ•ˆæœå³å¯ï¼š

![alt text](images/img-C.png)

æ‰“å¼€ [http://127.0.0.1:6006](http://127.0.0.1:6006) å®è·µæ•ˆæœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![alt text](images/img-9.png)

### 5.4 **å›¾ç‰‡ç†è§£å®æˆ˜ï¼ˆå¼€å¯ 50% A100 æƒé™åæ‰å¯å¼€å¯æ­¤ç« èŠ‚ï¼‰**

æ ¹æ®é™„å½• 6.4 çš„æ–¹æ³•ï¼Œå…³é—­å¹¶é‡æ–°å¯åŠ¨ä¸€ä¸ªæ–°çš„ `terminal`ï¼Œç»§ç»­è¾“å…¥æŒ‡ä»¤ï¼Œå¯åŠ¨ `InternLM-XComposer2-vl`ï¼š

```bash
conda activate demo

cd /root/demo/InternLM-XComposer
python /root/demo/InternLM-XComposer/examples/gradio_demo_chat.py  \
--code_path /root/models/internlm-xcomposer2-vl-7b \
--private \
--num_gpus 1 \
--port 6006
```

æ‰“å¼€ [http://127.0.0.1:6006](http://127.0.0.1:6006) (ä¸Šä¼ å›¾ç‰‡å) é”®å…¥å†…å®¹ç¤ºä¾‹å¦‚ä¸‹ï¼š

    è¯·åˆ†æä¸€ä¸‹å›¾ä¸­å†…å®¹

å®è·µæ•ˆæœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![alt text](images/img-7.png)

## 6 **é™„å½•**

### 6.1 **ï¼ˆå¯é€‰å‚è€ƒï¼‰ä»‹ç» `pip` æ¢æºåŠ `conda` æ¢æºæ–¹æ³•**
å¯¹äº `pip `æ¢æºï¼Œéœ€è¦ä¸´æ—¶ä½¿ç”¨é•œåƒæºå®‰è£…ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼šsome-package ä¸ºä½ éœ€è¦å®‰è£…çš„åŒ…å

```bash
pip install -i https://mirrors.cernet.edu.cn/pypi/web/simple some-package
```

è®¾ç½® `pip` é»˜è®¤é•œåƒæºï¼Œå‡çº§ `pip` åˆ°æœ€æ–°çš„ç‰ˆæœ¬ (>=10.0.0) åè¿›è¡Œé…ç½®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
python -m pip install --upgrade pip
pip config set global.index-url   https://mirrors.cernet.edu.cn/pypi/web/simple
```

å¦‚æœæ‚¨çš„ `pip` é»˜è®¤æºçš„ç½‘ç»œè¿æ¥è¾ƒå·®ï¼Œå¯ä»¥ä¸´æ—¶ä½¿ç”¨é•œåƒæºå‡çº§ `pip`ï¼š

```bash
python -m pip install -i https://mirrors.cernet.edu.cn/pypi/web/simple --upgrade pip
```

å¯¹äº `conda` æ¢æºï¼Œé•œåƒç«™æä¾›äº† `Anaconda` ä»“åº“ä¸ç¬¬ä¸‰æ–¹æºï¼ˆ`conda-forge`ã€`msys2`ã€`pytorch` ç­‰ï¼‰ï¼Œå„ç³»ç»Ÿéƒ½å¯ä»¥é€šè¿‡ä¿®æ”¹ç”¨æˆ·ç›®å½•ä¸‹çš„ `.condarc` æ–‡ä»¶æ¥ä½¿ç”¨é•œåƒç«™ã€‚ä¸åŒç³»ç»Ÿä¸‹çš„ `.condarc` ç›®å½•å¦‚ä¸‹ï¼š

- Linux: `${HOME}/.condarc`
- macOS: `${HOME}/.condarc`
- Windows: `C:\Users\<YourUserName>\.condarc`

æ³¨æ„ï¼š
- Windows ç”¨æˆ·æ— æ³•ç›´æ¥åˆ›å»ºåä¸º `.condarc` çš„æ–‡ä»¶ï¼Œå¯å…ˆæ‰§è¡Œ `conda config --set show_channel_urls yes` ç”Ÿæˆè¯¥æ–‡ä»¶ä¹‹åå†ä¿®æ”¹ã€‚

å¿«é€Ÿé…ç½®

```shell
cat <<'EOF' > ~/.condarc
channels:
- defaults
show_channel_urls: true
default_channels:
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
custom_channels:
conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
EOF
```

### 6.2 **ï¼ˆå¯é€‰å‚è€ƒï¼‰æ¨¡å‹ä¸‹è½½**

ä»¥ä¸‹ä¸‹è½½æ¨¡å‹çš„æ“ä½œä¸å»ºè®®å¤§å®¶åœ¨å¼€å‘æœºè¿›è¡Œå“¦ï¼Œåœ¨å¼€å‘æœºä¸‹è½½æ¨¡å‹ä¼šå ç”¨å¼€å‘æœºçš„å¤§é‡å¸¦å®½å’Œå†…å­˜ï¼Œä¸‹è½½ç­‰å¾…çš„æ—¶é—´ä¹Ÿä¼šæ¯”è¾ƒé•¿ï¼Œä¸åˆ©äºå¤§å®¶å­¦ä¹ ã€‚å¤§å®¶å¯ä»¥åœ¨è‡ªå·±çš„æœ¬åœ°ç”µè„‘å°è¯•å“¦~

#### 6.2.1 **Hugging Face**

ä½¿ç”¨ `Hugging Face` å®˜æ–¹æä¾›çš„ `huggingface-cli` å‘½ä»¤è¡Œå·¥å…·ã€‚å®‰è£…ä¾èµ–:

```bash
pip install -U huggingface_hub
```

ç„¶åæ–°å»º `python` æ–‡ä»¶ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼Œè¿è¡Œå³å¯ã€‚

+ resume-downloadï¼šæ–­ç‚¹ç»­ä¸‹
+ local-dirï¼šæœ¬åœ°å­˜å‚¨è·¯å¾„ã€‚

å…¶ä¸­ linux ç¯å¢ƒä¸‹éœ€è¦å¡«å†™ç»å¯¹è·¯å¾„.

```python
import os
# ä¸‹è½½æ¨¡å‹
os.system('huggingface-cli download --resume-download internlm/internlm2-chat-7b --local-dir your_path')
```

ä»¥ä¸‹å†…å®¹å°†å±•ç¤ºä½¿ç”¨ `huggingface_hub` ä¸‹è½½æ¨¡å‹ä¸­çš„éƒ¨åˆ†æ–‡ä»¶

```python
import os 
from huggingface_hub import hf_hub_download  # Load model directly 

hf_hub_download(repo_id="internlm/internlm2-7b", filename="config.json")
```

#### 6.2.2 **ModelScope**

ä½¿ç”¨ `modelscope` ä¸­çš„ `snapshot_download` å‡½æ•°ä¸‹è½½æ¨¡å‹ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ¨¡å‹åç§°ï¼Œå‚æ•° `cache_dir` ä¸ºæ¨¡å‹çš„ä¸‹è½½è·¯å¾„ã€‚

æ³¨æ„ï¼š`cache_dir` æœ€å¥½ä¸ºç»å¯¹è·¯å¾„ã€‚

å®‰è£…ä¾èµ–ï¼š

```bash
pip install modelscope==1.9.5
pip install transformers==4.35.2
```

åœ¨å½“å‰ç›®å½•ä¸‹æ–°å»º `python` æ–‡ä»¶ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼Œè¿è¡Œå³å¯ã€‚

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2-chat-7b', cache_dir='your path', revision='master')
```

#### 6.2.3 **OpenXLab**

`OpenXLab` å¯ä»¥é€šè¿‡æŒ‡å®šæ¨¡å‹ä»“åº“çš„åœ°å€ï¼Œä»¥åŠéœ€è¦ä¸‹è½½çš„æ–‡ä»¶çš„åç§°ï¼Œæ–‡ä»¶æ‰€éœ€ä¸‹è½½çš„ä½ç½®ç­‰ï¼Œç›´æ¥ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨ `download` å‡½æ•°å¯¼å…¥æ¨¡å‹ä¸­å¿ƒçš„æ¨¡å‹ã€‚

```python
import torch
import os
from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel
base_path = './local_files'
os.system('apt install git')
os.system('apt install git-lfs')
os.system(f'git clone https://code.openxlab.org.cn/Usr_name/repo_name.git {base_path}')
os.system(f'cd {base_path} && git lfs pull')
```

### 6.3 **ï¼ˆå¯é€‰å‚è€ƒï¼‰è½¯é“¾æ¥æ¸…é™¤æ–¹æ³•**

å½“æˆ‘ä»¬å»ºç«‹å®‰å…¨é“¾æ¥ä¹‹åï¼Œå¦‚æœæƒ³è¦å°†å…¶åˆ é™¤å¯ä»¥é€‰æ‹©ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
unlink link_name
```

æˆ‘ä»¬ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œå½“æˆ‘æƒ³åˆ é™¤è½¯é“¾æ¥ `/root/demo/internlm2-chat-7b` æ—¶ï¼š

```bash
cd /root/demo/
unlink internlm2-chat-7b
```

### 6.4 **ï¼ˆå¯é€‰å‚è€ƒï¼‰Terminal ç»ˆç«¯æ¸…é™¤æ–¹æ³•**

**åœ¨è¿è¡Œ `gradio` ç¨‹åºæ—¶ï¼Œå¦‚æœéœ€è¦é€€å‡ºï¼Œéœ€è¦æŒ‰ç…§å›¾ä¸­æ‰€ç¤ºæ­¥éª¤ï¼Œåœ¨ `terminal` æ ç›®ä¸­ç‚¹å‡»å…³é—­ï¼Œç„¶åå†é‡æ–°æ‰“å¼€ä¸€ä¸ª `terminal` ä»¥ç»§ç»­åé¢çš„å®éªŒã€‚ï¼ˆå¦åˆ™ä¼šå‡ºç° `æ˜¾å­˜è€—å°½` çš„æƒ…å†µï¼‰**

![alt text](images/check-3.png)

ä»¥ä¸Šç« èŠ‚å†…å®¹ä»…ä¾›å‚è€ƒï¼Œå¹¶ä¸ä½œä¸ºå¿…é¡»å®è·µçš„å†…å®¹ã€‚

## 7 **ä½œä¸š**

å®æˆ˜è¥ä½œä¸šè¢«æ”¾ç½®äº **[homework](homework.md)** æ–‡æ¡£ï¼Œå®Œæˆè¯¾ç¨‹åŸºç¡€ä½œä¸šå¯ä»¥åœ¨åç»­å­¦ä¹ ä¸­è·å¾—å‡çº§ç®—åŠ›çš„æœºä¼šå“¦ï¼
